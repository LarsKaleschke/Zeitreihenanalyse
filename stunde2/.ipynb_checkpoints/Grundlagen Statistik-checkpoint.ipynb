{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grundlagen der Wahrscheinlichkeitsrechnung und Statistik\n",
    "\n",
    "Dieser Abschnitt befasst sich mit den Grundlagen der Wahrscheinlichkeitstheorie in Hinblick auf die Zeitreihenanalyse. Zufallsvariablen sind darin Platzhalter für Messwerte eines Experiments.  Wahrscheinlichkeitsdichteverteilungen beschreibt die theoretische Verteilungsfunktion. Realisierungen eines Experimentes werden als Stichproben bezeichnet. Aus einer Anzahl von Realisierungen ergibt sich die empirische Häufigkeitsverteilung. \n",
    "\n",
    "## Zufallsvariable\n",
    "\n",
    "Sei $x(k)$ eine Menge von Zufallsvariablen. Die Zählvariable $k$ bezeichnet ein bestimmtes Ereignis. Die Zufallsvariable $x(k)$ beschreibt eine Messung mit einem zufälligen Ergebnis. Der Ausgang eines $N$-mal wiederholten Experiments ist eine Reihe von Punkten bzw. Messwerten. Die Messwerte werden Stichproben (Samples) bzw. Realisierungen genannt. Die Anzahl der Stichproben wird hier mit $N$ bezeichnet.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wahrscheinlichkeitsverteilungs- und dichtefunktion\n",
    "\n",
    "Die Wahrscheinlichkeitsverteilungsfunktion $P(x)$ wird definiert als die Wahrscheinlichkeit dafür, dass ein Ereignis $x(k)$ den Wert $x(k)\\le x$ annimmt.\n",
    "\n",
    "$$P(x)=\\operatorname{Prob}(x(k)\\le x)$$\n",
    "\n",
    "Es gilt\n",
    "\n",
    "$$P(a)\\le P(b)$$\n",
    "\n",
    "wenn $a\\le b$.\n",
    "\n",
    "Der Wertebereich von $P$ ist $[0,1]$ weil gilt \n",
    "\n",
    "$$P(-\\infty)=0, P(+\\infty)=1$$\n",
    "\n",
    "Wenn der Wertebereich der Zufallsvariable $x(k)$ kontinuierlich ist, dann wird die  Wahrscheinlichkeitsdichtefunktion $p(x)$  wie folgt definiert\n",
    "\n",
    "$$p(x)=\\lim_{\\Delta x\\to 0}\\left(\\frac{\\operatorname{Prob}(x<x(k)\\le x+\\Delta x)}{\\Delta x}\\right)$$\n",
    "\n",
    "Es gilt\n",
    "\n",
    "$$p(x)\\ge0$$\n",
    "\n",
    "$$\\int_{-\\infty}^{\\infty} p(x)dx=1$$\n",
    "\n",
    "$$P(x)=\\int_{-\\infty}^{x} p(\\zeta)d\\zeta$$ \n",
    "\n",
    "$$\\frac{dP(x)}{dx}=p(x)$$\n",
    "\n",
    "Die Wahrscheinlichkeitsdichtefunktionen diskreter Zufallsvariablen, wie z.B. der Würfelfunktion, müssen mit Hilfe von Delta-Funktionen $\\delta(x)$ oder als Summe beschrieben werden.\n",
    "\n",
    "$$\\operatorname{Prob}(x<x(k)\\le x+\\Delta x)=\\sum_x^{x+\\Delta x} p_k(x)$$\n",
    "\n",
    "mit $p_k=\\operatorname{Prob}(x(k)=x_k)$.\n",
    "\n",
    "Die Wahrscheinlichkeitsverteilungsfunktion $P(x)$ wird auch kumulative Verteilungsfunktion genannt. Sie ist definiert als das Integral über die Wahrscheinlichkeitsdichtefunktionen  $p(x)$. Oft genutzte Abkürzungen sind PDF und CDF für Probability Density Function $p(x)$ und Cumulative (Probability) Density Function $P(x)$.\n",
    "\n",
    "## Erwartungswert\n",
    "\n",
    "Der Erwartungswert einer Zufallsvariablen entspricht dem Mittelwert $\\mu_x$ bei unendlicher Wiederholung eines Experiments. Der Erwartungswert errechnet sich aus der Zufallsvariablen mittels Gewichtung mit der  Wahrscheinlichkeit \n",
    "\n",
    "$$\\operatorname{E}(x(k))=\\int_{-\\infty}^{\\infty} xp(x)dx=\\mu_x$$\n",
    "\n",
    "Für diskrete Zufallsvariablen ist das Integral durch eine Summe zu ersetzen. \n",
    "\n",
    "$$\\operatorname{E}(x)=\\sum_{k} x p_k(x) $$\n",
    "\n",
    "Die Varianz ist definiert als\n",
    "\n",
    "$$\\operatorname{E}(x(k)-\\operatorname{E}(x(k))^2)=\\sigma_x^2$$\n",
    "\n",
    "### Regeln\n",
    "\n",
    "Der Erwartungswert ist ein linearer Operator\n",
    "\n",
    "$$\\operatorname{E}(aX_1+bX_2 )=a\\operatorname{E}(X_1)+b\\operatorname{E}(X_2)$$\n",
    "\n",
    "\n",
    "\n",
    "### Beispiel Zufallsvariable Würfel\n",
    "\n",
    "Sei die Zufallsvariable $x(k)$ der Ausgang eines Würfelexperimentes. \n",
    "\n",
    "Beim idealen Würfel sind alle sechs Seiten gleichwahrscheinlich.\n",
    "\n",
    "$$P(x=1)=P(x=2)=P(x=3)=P(x=4)=P(x=5)=P(x=6)=\\frac{1}{6}$$\n",
    "\n",
    "Damit ergibt sich für den Erwartungswert \n",
    "\n",
    "$$\\operatorname{E}(x)=\\sum_{k=1}^{6} x_k p_k(x_k) $$\n",
    "\n",
    "mit $p_k(x)=\\frac{1}{6}$ für alle $x=1,2,..,6$\n",
    "\n",
    "$$\\operatorname{E}(x)=\\frac{1}{6}(1+2+3+4+5+6)=3.5$$\n",
    "\n",
    "### Übung\n",
    "\n",
    "Berechnen Sie Mittelwert und Varianz der Zufallsvariable $x(k)$ \"Würfel\" theoretisch und experimentell mit einem Zufallsgenerator. Skizzieren Sie die kumulative Wahrscheinlichkeitsverteilungsfunktion und $P(x_k)$ Wahrscheinlichkeitsdichtefunktionen $p(x_k)$.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kovarianz und Korrelation\n",
    "\n",
    "Der Korrelationskoeffizient $r$ beschreibt, wie eng zwei Zufallsvariablen in Raum oder Zeit zusammenhängen. Für zwei Zufallsvariablen $x=(x_1,x_2,...,x_n)$ und $y=(y_1,y_2,...,y_n)$ berechnet sich der Korrelationskoeffizient $r_{x,y}$ als\n",
    "\n",
    "$$r_{x,y}=\\frac{1}{N-1}\\sum_{i=1}^{N}\\frac{(x_i-\\bar{x})(y_i-\\bar{y})}{\\sigma_x \\sigma_y}$$\n",
    "\n",
    "oder ausgedrückt durch die Kovarianz $C_{x,y}$\n",
    "\n",
    "$$r_{x,y}=\\frac{C_{x,y}}{\\sigma_x \\sigma_y}$$\n",
    "\n",
    "dabei gilt\n",
    "\n",
    "$$C_{x,y}=\\operatorname{cov}(x,y)=\\sigma_{x,y}^2\\frac{1}{N-1}\\sum_{i=1}^{N} (x_i-\\bar{x})(y_i-\\bar{y})$$\n",
    "\n",
    "Der Korrelationskoeffizient errechnet sich aus der Kovarianz durch Normierung mit den Standardabweichungen $\\sigma_x$ und $\\sigma_y$ definiert durch\n",
    "\n",
    "$$\\sigma_x^2=\\sigma_x^2=\\frac{1}{N-1}\\sum_{i=1}^{N} (x_i-\\bar{x})^2$$\n",
    "\n",
    "Äquivalent ist die Definition der Kovarianz durch den Erwartungswert\n",
    "$$\\operatorname{cov}(x,y) = \\operatorname E\\bigl[(x - \\operatorname E(x)) \\cdot (y - \\operatorname E(y))\\bigr]$$\n",
    "\n",
    "Für statistisch unabhängige Zufallsvariablen $x$ und $y$ gilt $\\operatorname{cov}(x,y)=0$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalverteilung (z-Verteilung)\n",
    "\n",
    "<img src='Normalverteilung_plot.png'>\n",
    "\n",
    "\n",
    "Die Gaußverteilung ist gegeben durch\n",
    "\n",
    "$$p(x)=\\frac{1}{\\sigma_x\\sqrt{2\\pi}}e^{-\\frac{(x-\\mu_x)^2}{2\\sigma_x^2}}$$\n",
    "\n",
    "Es gilt\n",
    "\n",
    "$$E[x]=\\mu_x$$ \n",
    "\n",
    "und\n",
    "\n",
    "$$E[(x-\\mu_x)^2]=\\sigma_x^2$$\n",
    "\n",
    "Substitution von $z=\\frac{x-\\mu_x}{\\sigma_x}$ liefert die standardisierte Normalverteilung\n",
    "\n",
    "$$p(z)=\\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{z^2}{2}}$$\n",
    "\n",
    "für die gilt $E[x]=\\mu_z=0$ und  $E[(x-\\mu_z)^2]=\\sigma_z^2=1$\n",
    "\n",
    "Die Wahrscheinlichkeit $P$ berechnet sich aus dem Integral\n",
    "\n",
    "$$P(z_\\alpha)=\\int_{-\\infty}^{z_\\alpha} p(z)dz=Prob[z\\lt z_\\alpha]=1-\\alpha$$\n",
    "\n",
    "bzw. \n",
    "\n",
    "$$1-P(z_\\alpha)=\\int_{z_\\alpha}^{\\infty} p(z)dz=Prob[z \\gt z_\\alpha]=\\alpha$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaußsche Fehlerfunktion\n",
    "\n",
    "Als Fehlerfunktion oder [gaußsche Fehlerfunktion](http://de.wikipedia.org/wiki/Fehlerfunktion) bezeichnet man in der Theorie der Speziellen Funktionen das Integral\n",
    "\n",
    "$$\\operatorname{erf}(x) = \\frac 2{\\sqrt\\pi} \\int_0^x e^{-\\tau^2}\\,\\mathrm d\\tau$$\n",
    "\n",
    "Aus der Fehlerfunktion errechnet sich, wieviele Werte bei einer gegebenen Normalverteilung innerhalb eines Wertebereichs, z.B. $\\pm 1\\sigma$ zu erwarten sind.\n",
    "\n",
    "### Beispiel erf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68268949213708585"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "erf(1/sqrt(2)) % Octave/Matlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68268949213708585"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.special import erf\n",
    "from numpy import sqrt\n",
    "erf(1/sqrt(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95449973610364158"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "erf(2/sqrt(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99730020393673979"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "erf(3/sqrt(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im Intervall $\\pm \\sigma$ sind 68,27% aller Zufallswerte zu erwarten,\n",
    "in $\\pm 2\\sigma$ sind es 95,45%, in  $\\pm 3\\sigma$ erwarten wir 99,73%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter-Schätzungen\n",
    "\n",
    "Das Grundproblem der statistischen Analyse besteht darin, dass die Stichprobenanzahl begrenzt ist und die theoretischen Verteilungsfunktionen nicht bekannt sind. Stattdessen müssen statistische Parameter aus einer begrenzten Anzahl Stichproben möglichst genau geschätzt werden. \n",
    "\n",
    "Gegeben sei eine Zufallsvariable $x_i$, z.B. eine stochastische Zeitserie. Im Folgenden wird der Stichproben-Index $i$ weggelassen, um eine kompaktere Darstellung zu erhalten. Die beiden statistischen Parameter Mittelwert $\\mu$ und Varianz $\\sigma^2$ \n",
    "\n",
    "$$\\mu_x=E[x]=\\int_{-\\infty}^\\infty x p(x) dx$$\n",
    "$$\\sigma_x^2=E[(x-\\mu_x)^2]=\\int_{-\\infty}^\\infty (x-\\mu_x)^2  p(x) dx$$\n",
    "\n",
    "werden mit Hilfe der Wahrscheinlichkeitsdichtefunktion $p(x)$ theoretisch berechnet. Der Operator $E[]$ bezeichnet den Erwartungswert. Im Allgemeinen ist die Anzahl der Stichproben begrenzt und  die Wahrscheinlichkeitsdichtefunktion ist nicht bekannt. \n",
    "\n",
    "Eine (von vielen) Möglichkeiten um Mittelwert und Varianz von $x$ aus $N$ unabhängigen Messungen zu schätzen, ist gegeben durch\n",
    "\n",
    "$$\\bar{x}=\\hat{\\mu_x}=\\frac{1}{N} \\sum_{i=1}^N x_i $$\n",
    "$$s_b^2=\\hat{\\sigma_x}^2=\\frac{1}{N} \\sum_{i=1}^N (x_i-\\bar{x})^2 $$\n",
    "\n",
    "Der Unterschied von $\\hat{\\mu_x}$ und $\\mu_x$ besteht darin, dass $\\hat{\\mu_x}$ den geschätzen Wert und $\\mu_x$ den wahren bzw. theoretisch richtigen Wert bezeichnet.\n",
    "\n",
    "Wir wollen nun untersuchen, ob die Schätzung von Mittelwert und Varianz unsere Erwartungen erfüllt. Der Erwartungswert des Mittelwertes berechnet sich aus (Bendat und Piersol, 1986):\n",
    "\n",
    "$$E[\\bar{x}]=E\\left[\\frac{1}{N} \\sum_{i=1}^N x_i\\right]=\\frac{1}{N} E\\left[\\sum_{i=1}^N x_i\\right]=\\frac{1}{N}(N\\mu_x)=\\mu_x$$\n",
    "\n",
    "und erfüllt unsere Erwartungen $\\hat{\\mu_x}=\\bar{x}$ (erwartungstreu). \n",
    "\n",
    "Der mittlere quadratische Fehler der Schätzung des Mittelwertes ergibt sich aus\n",
    "\n",
    "$$E[(\\bar{x}-\\mu_x)^2]=E\\left[\\left(\\frac{1}{N} \\sum_{i=1}^N x_i-\\mu_x \\right)^2\\right]=\\frac{1}{N^2} E\\left[\\left(\\sum_{i=1}^N (x_i-\\mu_i)\\right)^2\\right]$$\n",
    "\n",
    "Die Messungen $x_i$ sind unabhängig, daher folgt\n",
    "\n",
    "$$E[(\\bar{x}-\\mu_x)^2]=\\frac{1}{N^2} E\\left[\\sum_{i=1}^N (x_i-\\mu_i)^2\\right]=\\frac{1}{N^2}(N\\sigma_x^2)=\\frac{\\sigma_x^2}{N}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Erwartungswert der Varianz $s_b$ errechnet sich zu \n",
    "\n",
    "$$E[s_b^2]=E[\\frac{1}{N} \\sum_{i=1}^N (x_i-\\bar{x})^2]=\\frac{1}{N} E[\\sum_{i=1}^N (x_i-\\bar{x})^2]=$$\n",
    "\n",
    "mit $\\sum_{i=1}^N (x_i-\\bar{x})^2=...=\\sum_{i=1}^N (x_i-\\bar{x})^2 - N(x_i-\\bar{x})^2$ und $E[(x_i-\\mu_x)^2]=\\sigma_x^2$ und $E[(\\bar{x}-\\mu_x)^2]=\\frac{\\sigma_x^2}{N}$ folgt (Herleitung siehe Bendat und Piersol, 1986)\n",
    "\n",
    "$$E[s_b^2]=\\frac{N-1}{N}\\sigma_x^2$$\n",
    "\n",
    "\n",
    "Die Varianz-Schätzung $s_b$ bzw. $\\hat{\\sigma_x}$  ist offensichtlich nicht erwartungstreu, da $\\hat{\\sigma_x}^2<\\sigma_x^2$. Die Schätzung nennt sich darum verzerrt oder biased. Eine erwartungstreue/unverzerrte Schätzung der Varianz ist gegeben durch\n",
    "\n",
    "$$s^2=\\hat{\\sigma_x}^2=\\frac{1}{N-1} \\sum_{i=1}^N (x_i-\\bar{x})^2 $$\n",
    "\n",
    "der sogennanten empirischen Varianz oder Stichprobenvarianz. Der Unterschied macht sich insbesondere für eine kleine Anzahl von Stichproben bemerkbar und kann für eine große Anzahl meist vernachlässigt werden. Vorsicht ist jedoch geboten bei Hypothesentests, die auf einem Vergleich der Varianz basieren.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesenprüfungen\n",
    "\n",
    "Bei einem statistischen Prüfverfahren wird einer sogenannten Nullhypothese eine (oder mehrere) Alternativhypothese gegenübergestellt. Im Sinne eines mathemathischen Widerspruchsbeweises wird die Nullhypothese statistisch widerlegt, um die Alternativhypothese zu beweisen. \n",
    "\n",
    "Bei der Auswahl eines Prüfverfahrens muss die theoretische Wahrscheinlichkeitsverteilung und der Stichprobenumfang beachtet werden. \n",
    "\n",
    "Das Ergebnis einer statistischen Prüfung ist immer im Zusammenhang mit dem sog. Signifikanzniveau zu nennen. Die zur Signifikanz komplementäre Größe ist die Irrtumswahrscheinlichkeit. Es gilt\n",
    "\n",
    "$$Signifikanz=1-Irrtumswahrscheinlichkeit$$\n",
    "\n",
    "oder\n",
    "\n",
    "$$Si=1-\\alpha$$\n",
    "\n",
    "Wahrscheinlichkeiten werden entweder in Prozent oder als Zahl zwischen 0-1 angeben.  Anstatt $\\alpha$ wird üblicherweise auch die Bezeichnung $p$ verwendet. Die Regel besagt, dass die Signifikanz groß ist, wenn $p$ klein ist.\n",
    "\n",
    "Aus der Angabe einer Wahrscheinlichkeit ergibt sich auch ein sog. Vertrauensbereich (auch Konfidenzintervall oder Mutungsbereich), der den Wertebereich für eine spezifische Wahrscheinlichkeit angibt.\n",
    "\n",
    "## Beschreibung von Wahrscheinlichkeitsbereichen (IPCC-Terminologie)\n",
    "\n",
    "Bei einer Einschätzung der Unsicherheit bestimmter Ergebnisse mittels fachkundiger Beurteilung und statistischer Analyse eines Beweises (z.B. Beobachtungen oder Modellergebnisse) werden folgende Wahrscheinlichkeitsbereiche verwendet, um die geschätzte Eintrittswahrscheinlichkeit auszudrücken:\n",
    "\n",
    " * praktisch sicher >99%\n",
    " * höchst wahrscheinlich >95%\n",
    " * sehr wahrscheinlich >90%\n",
    " * wahrscheinlich >66%\n",
    " * wahrscheinlicher als nicht >50%\n",
    " * etwa so wahrscheinlich wie nicht 33% bis 66%\n",
    " * unwahrscheinlich <33%\n",
    " * sehr unwahrscheinlich <10%\n",
    " * höchst unwahrscheinlich <5%\n",
    " * außergewöhnlich unwahrscheinlich <1%\n",
    "\n",
    "\n",
    "\n",
    "Übernommen aus [IPCC AR4 (2007)](http://www.ipcc.ch/pdf/reports-nonUN-translations/deutch/IPCC2007-SYR-SPM-german.pdf)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
